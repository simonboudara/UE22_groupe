{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1437\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'c:\\\\miniconda\\\\Lib\\\\site-packages\\\\tensorflow\\\\core\\\\protobuf\\\\tpu'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m      3\u001b[0m model2\u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      4\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m360\u001b[39m, \u001b[38;5;241m363\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m      5\u001b[0m     layers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m8\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m ])\n\u001b[0;32m     23\u001b[0m model2\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmycnn_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow_server_pb2\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_util\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_ops \u001b[38;5;28;01mas\u001b[39;00m cross_device_ops_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_device_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_util\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_utils\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_values\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reduce_util\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_utils.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_values \u001b[38;5;28;01mas\u001b[39;00m tpu_values_lib\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values \u001b[38;5;28;01mas\u001b[39;00m values_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreduce_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReduceOp\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\tpu_values.py:22\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various classes representing TPU distributed values.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mNote that the tests are in values_test.py .\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packed_distributed_variable \u001b[38;5;28;01mas\u001b[39;00m packed\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_replicated_variable\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_util\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\tpu_replicated_variable.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxla\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xla_sharding\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_util\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\distribute\\tpu_util.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_replication\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menclosing_tpu_context\u001b[39m():\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the TPUReplicateContext, which exists inside a tpu.rewrite().\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\tpu\\tpu_replication.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_ops\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variables\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_assignment \u001b[38;5;28;01mas\u001b[39;00m device_assignment_lib\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_ops\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core \u001b[38;5;28;01mas\u001b[39;00m core_types\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\tpu\\device_assignment.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtopology\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Topology\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     28\u001b[0m SINGLE_CORE_ASSIGNMENT \u001b[38;5;241m=\u001b[39m [[[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]]]\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\tensorflow\\python\\tpu\\topology.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Defines the `Topology` class, that describes a TPU fabric topology.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m topology_pb2\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tpu_device_name\u001b[39m(job, task, device):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1504\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1473\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1415\u001b[0m, in \u001b[0;36m_path_hooks\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen zipimport>:75\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model2= models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(360, 363, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,(2,2),activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.load_weights('mycnn_weights.h5')\n",
    "\n",
    "\n",
    "model2.summary()\n",
    "model2.compile(optimizer='adam',loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 358, 361, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 179, 180, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 177, 178, 128)     36992     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 88, 89, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 86, 87, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 43, 43, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 41, 41, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 20, 20, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 9, 9, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 64)          16448     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1048832   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1296648 (4.95 MB)\n",
      "Trainable params: 1296648 (4.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('mycnn_360_363')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17093 files belonging to 8 classes.\n",
      "Using 13675 files for training.\n",
      "Found 17093 files belonging to 8 classes.\n",
      "Using 13675 files for training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Create train dataset\n",
    "DATASET = 'snkd93bnjr-1\\PBC_dataset_normal_DIB\\PBC_dataset_normal_DIB'\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(DATASET, validation_split=0.2, subset='training', image_size=(360,363), seed=42, batch_size=16)  # set params\n",
    "\n",
    "# Create validation dataset\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(DATASET, validation_split=0.2, subset='training', image_size=(360,363), seed=42, batch_size=16)  # set params\n",
    "\n",
    "# Create test dataset\n",
    "test_ds = valid_ds.take(5)\n",
    "valid_ds = valid_ds.skip(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\miniconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "5/5 [==============================] - 5s 574ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.0384 - accuracy: 0.9750\n",
      "5/5 [==============================] - 2s 398ms/step - loss: 0.0453 - accuracy: 0.9750\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 408ms/step - loss: 0.0342 - accuracy: 0.9875\n",
      "5/5 [==============================] - 2s 409ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 0.0277 - accuracy: 0.9875\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 0.0356 - accuracy: 0.9875\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.0323 - accuracy: 0.9875\n",
      "5/5 [==============================] - 2s 430ms/step - loss: 0.0422 - accuracy: 0.9750\n",
      "0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "acc_moy =0\n",
    "for i in range (10):\n",
    "    acc_moy += model.evaluate(test_ds)[1]\n",
    "print(acc_moy/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15027 files belonging to 7 classes.\n",
      "Using 12022 files for training.\n",
      "Found 15027 files belonging to 7 classes.\n",
      "Using 12022 files for training.\n"
     ]
    }
   ],
   "source": [
    "#munich data\n",
    "DATASET = 'munich'\n",
    "train_ds_mun = tf.keras.utils.image_dataset_from_directory(DATASET, validation_split=0.2, subset='training', image_size=(360,363), seed=42, batch_size=16)  # set params\n",
    "\n",
    "# Create validation dataset\n",
    "valid_ds_mun = tf.keras.utils.image_dataset_from_directory(DATASET, validation_split=0.2, subset='training', image_size=(360,363), seed=42, batch_size=16)  # set params\n",
    "\n",
    "# Create test dataset\n",
    "test_ds_mun = valid_ds_mun.take(5)\n",
    "valid_ds_mun = valid_ds_mun.skip(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 633ms/step - loss: 8.6837 - accuracy: 0.2375\n",
      "5/5 [==============================] - 2s 401ms/step - loss: 10.0607 - accuracy: 0.2500\n",
      "5/5 [==============================] - 2s 367ms/step - loss: 10.6433 - accuracy: 0.1750\n",
      "5/5 [==============================] - 2s 382ms/step - loss: 7.9759 - accuracy: 0.2625\n",
      "5/5 [==============================] - 2s 360ms/step - loss: 8.6844 - accuracy: 0.2250\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 9.6457 - accuracy: 0.2375\n",
      "5/5 [==============================] - 2s 438ms/step - loss: 6.9982 - accuracy: 0.3375\n",
      "5/5 [==============================] - 2s 448ms/step - loss: 9.4578 - accuracy: 0.1875\n",
      "5/5 [==============================] - 3s 565ms/step - loss: 8.2223 - accuracy: 0.2125\n",
      "5/5 [==============================] - 3s 494ms/step - loss: 9.0805 - accuracy: 0.2250\n",
      "0.23499999791383744\n"
     ]
    }
   ],
   "source": [
    "acc_moy =0\n",
    "for i in range (10):\n",
    "    acc_moy += model.evaluate(test_ds_mun)[1]\n",
    "print(acc_moy/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (160,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 160, 160, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 160, 160, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 80, 80, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 80, 80, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 80, 80, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 40, 40, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 40, 40, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 40, 40, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 40, 40, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 20, 20, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 20, 20, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 10, 10, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"WBC\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " preprocess (Lambda)         (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 160, 160, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 160, 160, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 80, 80, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 80, 80, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 80, 80, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 40, 40, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 40, 40, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 40, 40, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 40, 40, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 20, 20, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 20, 20, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 20, 20, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 10, 10, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 10, 10, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12800)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 512)               6554112   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 256)               131328    \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21402184 (81.64 MB)\n",
      "Trainable params: 21402184 (81.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, RandomFlip, RandomRotation, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.summary()\n",
    "\n",
    "top_net = [\n",
    "    Dropout(0.3, seed=2022, name='dropout'),\n",
    "    Flatten('channels_last', name='flatten'),\n",
    "    Dense(512, activation='relu', name='fc1'),\n",
    "    Dense(256, activation='relu', name='fc2'),\n",
    "    Dense(8, activation='softmax', name='predictions')\n",
    "]\n",
    "\n",
    "inputs = Input(shape=IMG_SHAPE, name='input')\n",
    "preprocess_input = Lambda(lambda x: tf.keras.applications.vgg16.preprocess_input(x), name='preprocess')\n",
    "x = preprocess_input(inputs)\n",
    "for layer in base_model.layers[1:]:\n",
    "    x = layer(x)\n",
    "\n",
    "# On ajoute notre réseau de classification à 8 classes\n",
    "for layer in top_net[:-1]:\n",
    "    x = layer(x)\n",
    "outputs = top_net[-1](x)\n",
    "\n",
    "model_tl = Model(inputs, outputs, name='WBC')\n",
    "\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'ProjetInfoS2_grouoe\\\\PBC_dataset_normal_DIB_224\\\\PBC_dataset_normal_DIB_224'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m conv5_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minputs,outputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m     12\u001b[0m conv6_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minputs,outputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m---> 14\u001b[0m classes \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBC_dataset_normal_DIB_224\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPBC_dataset_normal_DIB_224\u001b[39m\u001b[38;5;124m'\u001b[39m,name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProjetInfoS2_grouoe\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPBC_dataset_normal_DIB_224\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPBC_dataset_normal_DIB_224\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     15\u001b[0m random_classe \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(classes)\n\u001b[0;32m     16\u001b[0m images \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(random_classe, name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(random_classe)]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'ProjetInfoS2_grouoe\\\\PBC_dataset_normal_DIB_224\\\\PBC_dataset_normal_DIB_224'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "conv1_model = tf.keras.Model(inputs=model.inputs,outputs=model.layers[0].output)\n",
    "conv2_model =tf.keras.Model(inputs=model.inputs,outputs=model.layers[2].output)\n",
    "conv3_model = tf.keras.Model(inputs=model.inputs,outputs=model.layers[4].output)\n",
    "conv4_model = tf.keras.Model(inputs=model.inputs,outputs=model.layers[6].output)\n",
    "conv5_model = tf.keras.Model(inputs=model.inputs,outputs=model.layers[8].output)\n",
    "conv6_model = tf.keras.Model(inputs=model.inputs,outputs=model.layers[10].output)\n",
    "\n",
    "classes = [os.path.join('PBC_dataset_normal_DIB_224\\PBC_dataset_normal_DIB_224',name) for name in os.listdir('ProjetInfoS2_grouoe\\PBC_dataset_normal_DIB_224\\PBC_dataset_normal_DIB_224')]\n",
    "random_classe = random.choice(classes)\n",
    "images = [os.path.join(random_classe, name) for name in os.listdir(random_classe)]\n",
    "random_image = random.choice(images)\n",
    "print(\"L'image initiale choisie par le programme : \")\n",
    "print(random_image)\n",
    "image_c = tf.keras.preprocessing.image.load_img(random_image, target_size=(360, 363, 3))\n",
    "image_b=image_c\n",
    "\n",
    "save_dir = 'activations_images2'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "image_basename = os.path.basename(random_image)\n",
    "save_path = os.path.join(save_dir, image_basename)\n",
    "shutil.copy(random_image, save_path)\n",
    "\n",
    "image_b=tf.keras.preprocessing.image.img_to_array(image_b)\n",
    "image_b = tf.keras.applications.vgg16.preprocess_input(image_b)\n",
    "image_b = tf.expand_dims(image_b, axis=0)\n",
    "plt.imshow(image_b[0,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image_c = tf.keras.preprocessing.image.img_to_array(image_c)\n",
    "image_c = tf.keras.applications.vgg16.preprocess_input(image_c)\n",
    "image_c = tf.expand_dims(image_c, axis=0)\n",
    "image_b = image_c\n",
    "print(image_c.shape)\n",
    "\n",
    "conv_output = conv1_model.predict(image_c)\n",
    "print(conv_output.shape)\n",
    "\n",
    "for j in range (0,32):\n",
    "  print('Couche 1 filtre', j )\n",
    "  filter_image=conv_output[0,:,:,j]\n",
    "  filter_image = (filter_image - filter_image.min()) / (filter_image.max() - filter_image.min())\n",
    "  filter_image_pil = Image.fromarray((filter_image * 255).astype(np.uint8))  # Convertir en image PIL\n",
    "  filter_image_pil.save(f'{save_dir}/Couche{1}_filtre{j}.png')\n",
    "  plt.imshow(conv_output[0, :, :, j])\n",
    "  plt.show()\n",
    "\n",
    "conv_output2= conv2_model.predict(image_c)\n",
    "\n",
    "plt.imshow(conv_output2[0,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "for j in range (0,64):\n",
    "  print('Couche 2 filtre', j )\n",
    "  filter_image=conv_output2[0,:,:,j]\n",
    "  filter_image = (filter_image - filter_image.min()) / (filter_image.max() - filter_image.min())\n",
    "  filter_image_pil = Image.fromarray((filter_image * 255).astype(np.uint8))  # Convertir en image PIL\n",
    "  filter_image_pil.save(f'{save_dir}/Couche{2}_filtre{j}.png')\n",
    "  plt.imshow(conv_output2[0, :, :, j])\n",
    "  plt.show()\n",
    "\n",
    "conv_output3 = conv3_model.predict(image_c)\n",
    "for i in range (0,64):\n",
    "  print('Couche 3 filtre', i)\n",
    "  filter_image=conv_output3[0,:,:,i]\n",
    "  filter_image = (filter_image - filter_image.min()) / (filter_image.max() - filter_image.min())\n",
    "  filter_image_pil = Image.fromarray((filter_image * 255).astype(np.uint8))  # Convertir en image PIL\n",
    "  filter_image_pil.save(f'{save_dir}/Couche{3}_filtre{i}.png')\n",
    "  plt.imshow(conv_output3[0,:,:,i])\n",
    "  plt.show()\n",
    "\n",
    "conv_output4 = conv4_model.predict(image_c)\n",
    "for i in range (0,64):\n",
    "  print('Couche 4 filtre', i)\n",
    "  filter_image=conv_output4[0,:,:,i]\n",
    "  filter_image = (filter_image - filter_image.min()) / (filter_image.max() - filter_image.min())\n",
    "  filter_image_pil = Image.fromarray((filter_image * 255).astype(np.uint8))  # Convertir en image PIL\n",
    "  filter_image_pil.save(f'{save_dir}/Couche{4}_filtre{i}.png')\n",
    "  plt.imshow(conv_output4[0,:,:,i])\n",
    "  plt.show()\n",
    "\n",
    "conv_output5 = conv5_model.predict(image_c)\n",
    "for i in range (0,64):\n",
    "  print('Couche 5 filtre', i)\n",
    "  filter_image=conv_output5[0,:,:,i]\n",
    "  filter_image = (filter_image - filter_image.min()) / (filter_image.max() - filter_image.min())\n",
    "  filter_image_pil = Image.fromarray((filter_image * 255).astype(np.uint8))  # Convertir en image PIL\n",
    "  filter_image_pil.save(f'{save_dir}/Couche{5}_filtre{i}.png')\n",
    "  plt.imshow(conv_output5[0,:,:,i])\n",
    "  plt.show()\n",
    "\n",
    "conv_output6 = conv6_model.predict(image_c)\n",
    "for i in range (0,64):\n",
    "  print('Couche 6 filtre', i)\n",
    "  filter_image=conv_output2[0,:,:,i]\n",
    "  filter_image = (filter_image - filter_image.min()) / (filter_image.max() - filter_image.min())\n",
    "  filter_image_pil = Image.fromarray((filter_image * 255).astype(np.uint8))  # Convertir en image PIL\n",
    "  filter_image_pil.save(f'{save_dir}/Couche{6}_filtre{i}.png')\n",
    "  plt.imshow(conv_output6[0,:,:,i])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 360, 363, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 360, 363, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 360, 363, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 180, 181, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 180, 181, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 180, 181, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 90, 90, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 90, 90, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 90, 90, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 90, 90, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 45, 45, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 45, 45, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 45, 45, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 45, 45, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 22, 22, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "base_model = tf.keras.applications.VGG16(input_shape=(360,363,3), include_top=False, weights='imagenet')\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, RandomFlip, RandomRotation, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "IMG_SHAPE =(360,363,3)\n",
    "\n",
    "base_model = tf.keras.applications.VGG16(input_shape=(360,363,3), include_top=False, weights='imagenet')\n",
    "\n",
    "top_net = [\n",
    "    Dropout(0.3, seed=2022, name='dropout'),\n",
    "    Flatten('channels_last', name='flatten'),\n",
    "    Dense(512, activation='relu', name='fc1'),\n",
    "    Dense(256, activation='relu', name='fc2'),\n",
    "    Dense(8, activation='softmax', name='predictions')\n",
    "]\n",
    "\n",
    "# Créer une première couche d'INPUT -> entrée de la prochaine couche du CNN f(g(x))\n",
    "inputs = Input(shape=IMG_SHAPE, name='input')\n",
    "\n",
    "# On embarque la couche de preprocessing dans une fonction Lambda car sinon on arrive pas à sauvegarder le modèle\n",
    "preprocess_input = Lambda(lambda x: tf.keras.applications.vgg16.preprocess_input(x), name='preprocess')\n",
    "x = preprocess_input(inputs)\n",
    "\n",
    "# x permet de créer un graphe de liasion entres les différentes couches \n",
    "for layer in base_model.layers[1:]:\n",
    "    x = layer(x)\n",
    "\n",
    "# On ajoute notre réseau de classification à 8 classes\n",
    "for layer in top_net[:-1]:\n",
    "    x = layer(x)\n",
    "outputs = top_net[-1](x)\n",
    "\n",
    "model_tl = Model(inputs, outputs, name='WBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "IMG_SHAPE = (360,363,3)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, RandomFlip, RandomRotation, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "top_net = [\n",
    "    Dropout(0.3, seed=2022, name='dropout'),\n",
    "    Flatten('channels_last', name='flatten'),\n",
    "    Dense(512, activation='relu', name='fc1'),\n",
    "    Dense(256, activation='relu', name='fc2'),\n",
    "    Dense(8, activation='softmax', name='predictions')\n",
    "]\n",
    "\n",
    "inputs = Input(shape=IMG_SHAPE, name='input')\n",
    "\n",
    "preprocess_input = Lambda(lambda x: tf.keras.applications.vgg16.preprocess_input(x), name='preprocess')\n",
    "x = preprocess_input(inputs)\n",
    "\n",
    "\n",
    "for layer in base_model.layers[1:]:\n",
    "    x = layer(x)\n",
    "\n",
    "for layer in top_net[:-1]:\n",
    "    x = layer(x)\n",
    "outputs = top_net[-1](x)\n",
    "\n",
    "model_ft = Model(inputs, outputs, name='WBC')\n",
    "\n",
    "LAST_CONV_BLOCK_NAME = 'block5_conv1'\n",
    "for layer in model.layers:\n",
    "    if layer.name == LAST_CONV_BLOCK_NAME:\n",
    "        break\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "model_ft.load_weights('cnn_ft_weights_360_363.h5')\n",
    "base_learning_rate = 0.0001\n",
    "model_ft.compile(optimizer=Adam(learning_rate=base_learning_rate),\n",
    "            loss=SparseCategoricalCrossentropy(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 19s 4s/step - loss: 4.5025 - accuracy: 0.5375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.5024824142456055, 0.5375000238418579]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.evaluate(test_ds_mun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_tl = tf.keras.models.load_model('model_tl_360_363')\n",
    "model_cnn = tf.keras.models.load_model('mycnn_360_363')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 460ms/step - loss: 10.0607 - accuracy: 0.2500\n",
      "5/5 [==============================] - 25s 4s/step - loss: 8.7115 - accuracy: 0.4500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.711496353149414, 0.44999998807907104]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.evaluate(test_ds_mun)\n",
    "model_tl.evaluate(test_ds_mun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_ft_360_363\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_ft_360_363\\assets\n"
     ]
    }
   ],
   "source": [
    "model_ft.save('model_ft_360_363')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 20s 4s/step - loss: 0.1699 - accuracy: 0.9750\n",
      "5/5 [==============================] - 27s 6s/step - loss: 0.1829 - accuracy: 0.9625\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.2186 - accuracy: 0.9500\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.2833 - accuracy: 0.9500\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.2173 - accuracy: 0.9625\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.2030 - accuracy: 0.9625\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1596 - accuracy: 0.9625\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.3263 - accuracy: 0.9500\n",
      "5/5 [==============================] - 43s 8s/step - loss: 0.3318 - accuracy: 0.9375\n",
      "5/5 [==============================] - 23s 4s/step - loss: 0.1617 - accuracy: 0.9375\n",
      "0.9549999892711639\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range (10):\n",
    "    acc+=model.evaluate(test_ds)[1]\n",
    "print(acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TakeDataset element_spec=(TensorSpec(shape=(None, 360, 363, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"snkd93bnjr-1\\PBC_dataset_normal_DIB\\PBC_dataset_normal_DIB\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(DATASET, validation_split=0.2, subset='training', image_size=(360,363), seed=42, batch_size=16)  # set params\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(DATASET, validation_split=0.2, subset='training', image_size=(360,363), seed=42, batch_size=16)  # set params\n",
    "test_ds = valid_ds.take(2)\n",
    "valid_ds = valid_ds.skip(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
